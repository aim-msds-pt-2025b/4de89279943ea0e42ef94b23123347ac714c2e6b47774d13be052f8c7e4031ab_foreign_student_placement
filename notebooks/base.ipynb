{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe68b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & Data Preprocessing\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_data(path: str,\n",
    "                    test_size: float = 0.2,\n",
    "                    random_state: int = 42):\n",
    "    \"\"\"\n",
    "    1) Load CSV\n",
    "    2) Drop identifier/leakage columns\n",
    "    3) Map target to binary\n",
    "    4) Drop rows with missing core columns\n",
    "    5) Split into train/test\n",
    "    6) Scale numeric features\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # drop leakage columns\n",
    "    drop_cols = [\n",
    "        \"student_id\",\"destination_city\",\"university_name\",\n",
    "        \"course_name\",\"placement_country\",\"placement_company\",\n",
    "        \"starting_salary_usd\"\n",
    "    ]\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "\n",
    "    # binary target\n",
    "    df[\"placement_status\"] = df[\"placement_status\"]\\\n",
    "        .map({\"Placed\":1,\"Not Placed\":0})\n",
    "\n",
    "    # drop missing in core\n",
    "    core = [\n",
    "        \"placement_status\",\"gpa_or_score\",\"test_score\",\n",
    "        \"field_of_study\",\"origin_country\",\"destination_country\",\n",
    "        \"scholarship_received\",\"enrollment_reason\",\n",
    "        \"language_proficiency_test\",\"visa_status\",\n",
    "        \"post_graduation_visa\",\"graduation_year\",\n",
    "        \"year_of_enrollment\"\n",
    "    ]\n",
    "    df = df.dropna(subset=core)\n",
    "\n",
    "    # split\n",
    "    X = df.drop(\"placement_status\", axis=1)\n",
    "    y = df[\"placement_status\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size,\n",
    "        random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # scale numeric\n",
    "    num_cols = [\"gpa_or_score\",\"test_score\",\"year_of_enrollment\",\"graduation_year\"]\n",
    "    scaler = StandardScaler().fit(X_train[num_cols])\n",
    "    X_train[num_cols] = scaler.transform(X_train[num_cols])\n",
    "    X_test[num_cols]  = scaler.transform(X_test[num_cols])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca2fbdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Feature Engineering\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def engineer_features(X_train: pd.DataFrame,\n",
    "                      X_test:  pd.DataFrame):\n",
    "    \"\"\"\n",
    "    1) interactions, ratios, polynomials\n",
    "    2) bucketize & count-encode & combine cats\n",
    "    3) clustering\n",
    "    4) one-hot & align\n",
    "    \"\"\"\n",
    "    # apply to both\n",
    "    for df in (X_train, X_test):\n",
    "        df[\"study_duration\"]       = df[\"graduation_year\"] - df[\"year_of_enrollment\"]\n",
    "        df[\"gpa_test_interaction\"] = df[\"gpa_or_score\"] * df[\"test_score\"]\n",
    "        df[\"study_duration_sq\"]    = df[\"study_duration\"] ** 2\n",
    "        df[\"gpa_test_ratio\"]       = df[\"gpa_or_score\"] / (df[\"test_score\"]+1e-3)\n",
    "\n",
    "        # buckets\n",
    "        df[\"gpa_bucket\"]  = pd.qcut(df[\"gpa_or_score\"],3,labels=False)\n",
    "        df[\"test_bucket\"] = pd.qcut(df[\"test_score\"],3,labels=False)\n",
    "\n",
    "        # count-encode\n",
    "        freq = df[\"enrollment_reason\"].value_counts()\n",
    "        df[\"enroll_reason_count\"] = df[\"enrollment_reason\"]\\\n",
    "            .map(freq).fillna(0).astype(int)\n",
    "\n",
    "        # combined cat\n",
    "        df[\"scholarship_visa_combo\"] = (\n",
    "            df[\"scholarship_received\"].astype(str)\n",
    "            + \"_\" + df[\"visa_status\"].astype(str)\n",
    "        )\n",
    "\n",
    "    # clustering\n",
    "    cols = [\"gpa_or_score\",\"test_score\",\"study_duration\"]\n",
    "    kmeans = KMeans(n_clusters=5,random_state=42)\n",
    "    X_train[\"num_cluster\"] = kmeans.fit_predict(X_train[cols])\n",
    "    X_test[\"num_cluster\"]  = kmeans.predict(X_test[cols])\n",
    "\n",
    "    # one-hot & align\n",
    "    X_train = pd.get_dummies(X_train,drop_first=True)\n",
    "    X_test  = pd.get_dummies(X_test, drop_first=True)\n",
    "    X_train, X_test = X_train.align(X_test,join=\"left\",axis=1,fill_value=0)\n",
    "\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "411fef77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforest': '../models/model_randomforest.pkl',\n",
       " 'logisticregression': '../models/model_logisticregression.pkl',\n",
       " 'gradientboosting': '../models/model_gradientboosting.pkl',\n",
       " 'svm': '../models/model_svm.pkl',\n",
       " 'knn': '../models/model_knn.pkl'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 (updated): Train & Save Multiple Models\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "\n",
    "# suppress the convergence warning so it doesnâ€™t spam your output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "models = {\n",
    "    \"randomforest\":       RandomForestClassifier(random_state=42),\n",
    "    \"logisticregression\": LogisticRegression(\n",
    "                              solver=\"saga\",\n",
    "                              max_iter=5000,\n",
    "                              random_state=42,\n",
    "                              n_jobs=-1\n",
    "                          ),\n",
    "    \"gradientboosting\":   GradientBoostingClassifier(random_state=42),\n",
    "    \"svm\":                SVC(probability=True, random_state=42),\n",
    "    \"knn\":                KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "saved_models = {}\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train_fe, y_train)\n",
    "    path = f\"../models/model_{name}.pkl\"\n",
    "    joblib.dump(clf, path)\n",
    "    saved_models[name] = path\n",
    "\n",
    "saved_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Evaluate All Saved Models\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Iterate over each saved model, compute metrics on the engineered test set\n",
    "results = []\n",
    "for name, path in saved_models.items():\n",
    "    model = joblib.load(path)\n",
    "    y_pred = model.predict(X_test_fe)\n",
    "    results.append({\n",
    "        \"model\":    name,\n",
    "        \"accuracy\":  accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"recall\":    recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"f1_score\":  f1_score(y_test, y_pred, zero_division=0)\n",
    "    })\n",
    "\n",
    "# Create a DataFrame for easy comparison\n",
    "metrics_df = pd.DataFrame(results).set_index(\"model\")\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f776c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics: {'accuracy': 0.49129353233830847, 'precision': 0.49166666666666664, 'recall': 0.4392059553349876, 'f1_score': 0.4639580602883355}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.49129353233830847,\n",
       " 'precision': 0.49166666666666664,\n",
       " 'recall': 0.4392059553349876,\n",
       " 'f1_score': 0.4639580602883355}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: Full Pipeline Execution\n",
    "\n",
    "# 1) Load & preprocess\n",
    "X_train, X_test, y_train, y_test = preprocess_data(\n",
    "    \"../data/global_student_migration.csv\"\n",
    ")\n",
    "\n",
    "# 2) Feature engineering\n",
    "X_train_fe, X_test_fe = engineer_features(X_train, X_test)\n",
    "\n",
    "# 3) Train & save\n",
    "model = train_model(\n",
    "    X_train_fe, y_train,\n",
    "    model_path=\"../models/model.pkl\"\n",
    ")\n",
    "\n",
    "# 4) Evaluate & save metrics\n",
    "metrics = evaluate_model(\n",
    "    model, X_test_fe, y_test,\n",
    "    metrics_path=\"../reports/metrics.txt\"\n",
    ")\n",
    "\n",
    "# 5) Display results\n",
    "print(\"Evaluation metrics:\", metrics)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34689c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
