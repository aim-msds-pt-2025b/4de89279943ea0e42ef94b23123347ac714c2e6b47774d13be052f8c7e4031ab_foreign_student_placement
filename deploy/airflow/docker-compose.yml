services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db:/var/lib/postgresql/data

  webserver:
    image: apache/airflow:2.9.3
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock
      # Mount the HOST data & models dirs into named volumes in the Docker daemon:
      - hw2_data:/opt/airflow/data # so the volume hw2_data points at your ./../../data
      - hw2_models:/opt/airflow/models # and hw2_models points at ./../../models
    ports:
      - "8080:8080"
    entrypoint:
      - bash
      - -cx
      - |
        pip install --no-cache-dir -r /requirements.txt
        exec airflow webserver

  scheduler:
    image: apache/airflow:2.9.3
    depends_on:
      - webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock
      - hw2_data:/opt/airflow/data
      - hw2_models:/opt/airflow/models
    entrypoint:
      - bash
      - -cx
      - |
        pip install --no-cache-dir -r /requirements.txt
        exec airflow scheduler

volumes:
  postgres-db:
  hw2_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${PWD}/../../data"
  hw2_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${PWD}/../../models"
